"""
M√ìDULO DE AN√ÅLISIS EXPLORATORIO (EDA) PARA BOGOT√Å APARTMENTS
An√°lisis completo, autom√°tico y profesional del dataset inmobiliario
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
import logging
import warnings
from matplotlib.gridspec import GridSpec
import os

warnings.filterwarnings('ignore')

class BogotaApartmentsEDA:
    """
    Clase para an√°lisis exploratorio completo de dataset de apartamentos en Bogot√°
    """
    
    def __init__(self, file_path=None):
        """
        Inicializar el analizador EDA
        
        Args:
            file_path (str): Ruta al archivo Excel (opcional)
        """
        self.df = None
        self.file_path = file_path
        self.numeric_columns = []
        self.categorical_columns = []
        self.analysis_results = {}
        
        # Configuraci√≥n de estilo
        plt.style.use('seaborn-v0_8-whitegrid')
        sns.set_palette("husl")
        self.colors = ['#2E86AB', '#A23B72', '#F18F01', '#C73E1D', '#3F7CAC']
        
        # Configurar logging
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s'
        )
        self.logger = logging.getLogger(__name__)
        
        # Cargar datos si se proporciona file_path
        if file_path:
            self.load_data(file_path)
    
    def load_data(self, file_path):
        """
        Cargar datos desde archivo Excel
        
        Args:
            file_path (str): Ruta al archivo Excel
        """
        self.logger.info(f"üì• Cargando datos desde: {file_path}")
        try:
            self.df = pd.read_excel(file_path)
            self.file_path = file_path
            
            # Definir columnas de inter√©s
            self.original_columns = [
                'precio_venta', 'area', 'habitaciones', 'banos', 'estrato', 
                'parqueaderos', 'administracion', 'localidad', 'barrio', 'antiguedad',
                'latitud', 'longitud', 'tipo_propiedad', 'precio_arriendo'
            ]
            
            # Filtrar solo columnas que existan
            available_columns = [col for col in self.original_columns if col in self.df.columns]
            self.df = self.df[available_columns]
            
            # Clasificar columnas
            self.numeric_columns = self.df.select_dtypes(include=[np.number]).columns.tolist()
            self.categorical_columns = self.df.select_dtypes(include=['object']).columns.tolist()
            
            self.logger.info(f"‚úÖ Datos cargados: {self.df.shape[0]:,} registros, {self.df.shape[1]} columnas")
            self.logger.info(f"üìä Num√©ricas: {len(self.numeric_columns)}, Categ√≥ricas: {len(self.categorical_columns)}")
            
        except Exception as e:
            self.logger.error(f"‚ùå Error cargando datos: {e}")
            raise
    
    def generate_complete_report(self, save_plots=False, plot_dir='eda_plots'):
        """
        Generar reporte EDA completo
        
        Args:
            save_plots (bool): Guardar gr√°ficos en archivos
            plot_dir (str): Directorio para guardar gr√°ficos
        """
        self.logger.info("üöÄ INICIANDO REPORTE EDA COMPLETO")
        
        if self.df is None:
            self.logger.error("‚ùå No hay datos cargados. Use load_data() primero.")
            return
        
        # Crear directorio para gr√°ficos si es necesario
        if save_plots and not os.path.exists(plot_dir):
            os.makedirs(plot_dir)
        
        try:
            # 1. Resumen general
            self._print_dataset_overview()
            
            # 2. An√°lisis de valores faltantes
            missing_analysis = self._analyze_missing_values()
            
            # 3. An√°lisis num√©rico
            numeric_stats = self._analyze_numeric_variables(save_plots, plot_dir)
            
            # 4. An√°lisis categ√≥rico
            categorical_stats = self._analyze_categorical_variables(save_plots, plot_dir)
            
            # 5. An√°lisis de correlaciones
            correlation_analysis = self._analyze_correlations(save_plots, plot_dir)
            
            # 6. An√°lisis de relaciones con precio
            price_analysis = self._analyze_price_relationships(save_plots, plot_dir)
            
            # 7. Detecci√≥n de problemas
            issues = self._detect_potential_issues(missing_analysis, numeric_stats)
            
            # 8. Recomendaciones
            self._provide_preprocessing_recommendations(issues, numeric_stats, missing_analysis)
            
            # 9. Resumen ejecutivo
            self._generate_executive_summary(missing_analysis, numeric_stats, issues)
            
            self.logger.info("üéâ REPORTE EDA COMPLETADO EXITOSAMENTE")
            
            return {
                'missing_analysis': missing_analysis,
                'numeric_stats': numeric_stats,
                'categorical_stats': categorical_stats,
                'correlation_analysis': correlation_analysis,
                'issues': issues
            }
            
        except Exception as e:
            self.logger.error(f"‚ùå Error en el reporte EDA: {e}")
            raise
    
    def _print_dataset_overview(self):
        """Imprimir resumen general del dataset"""
        print("=" * 80)
        print("üè¢ AN√ÅLISIS EXPLORATORIO - BOGOT√Å APARTMENTS")
        print("=" * 80)
        
        print(f"üìä DIMENSIONES: {self.df.shape[0]:,} registros √ó {self.df.shape[1]} columnas")
        print(f"üéØ VARIABLE OBJETIVO: precio_venta")
        print(f"üíæ MEMORIA: {self.df.memory_usage(deep=True).sum() / 1024**2:.1f} MB")
        
        print("\nüìù TIPOS DE DATOS:")
        type_counts = self.df.dtypes.value_counts()
        for dtype, count in type_counts.items():
            print(f"   ‚Ä¢ {dtype}: {count} columnas")
        
        print("\nüîç COLUMNAS DISPONIBLES:")
        print(f"   ‚Ä¢ Num√©ricas ({len(self.numeric_columns)}): {', '.join(self.numeric_columns)}")
        print(f"   ‚Ä¢ Categ√≥ricas ({len(self.categorical_columns)}): {', '.join(self.categorical_columns)}")
        print("=" * 80)
    
    def _analyze_missing_values(self):
        """Analizar valores faltantes"""
        self.logger.info("üîç Analizando valores faltantes...")
        
        print("\n" + "üîç AN√ÅLISIS DE VALORES FALTANTES")
        print("-" * 50)
        
        missing_data = self.df.isnull().sum()
        missing_percent = (missing_data / len(self.df)) * 100
        
        missing_df = pd.DataFrame({
            'Valores_Faltantes': missing_data,
            'Porcentaje': missing_percent
        }).sort_values('Porcentaje', ascending=False)
        
        # Filtrar solo columnas con valores faltantes
        missing_df = missing_df[missing_df['Valores_Faltantes'] > 0]
        
        if len(missing_df) > 0:
            print("üìã COLUMNAS CON VALORES FALTANTES:")
            for col, row in missing_df.iterrows():
                print(f"   ‚ö†Ô∏è  {col}: {row['Valores_Faltantes']} ({row['Porcentaje']:.1f}%)")
            
            # Visualizaci√≥n
            self._plot_missing_values(missing_df)
        else:
            print("‚úÖ No hay valores faltantes en el dataset")
        
        return missing_df
    
    def _plot_missing_values(self, missing_df):
        """Visualizar valores faltantes"""
        plt.figure(figsize=(12, 6))
        
        # Tomar top 15 columnas con missing values
        plot_data = missing_df.head(15)
        
        bars = plt.bar(plot_data.index, plot_data['Porcentaje'], 
                      color=self.colors[0], alpha=0.7, edgecolor='black')
        
        plt.title('Porcentaje de Valores Faltantes por Columna', 
                 fontsize=14, fontweight='bold', pad=20)
        plt.ylabel('Porcentaje Faltante (%)')
        plt.xticks(rotation=45, ha='right')
        plt.grid(axis='y', alpha=0.3)
        
        # A√±adir etiquetas
        for bar in bars:
            height = bar.get_height()
            plt.text(bar.get_x() + bar.get_width()/2., height + 0.5,
                    f'{height:.1f}%', ha='center', va='bottom', fontweight='bold')
        
        plt.tight_layout()
        plt.show()
    
    def _analyze_numeric_variables(self, save_plots=False, plot_dir='eda_plots'):
        """An√°lisis exhaustivo de variables num√©ricas"""
        self.logger.info("üìà Analizando variables num√©ricas...")
        
        if not self.numeric_columns:
            self.logger.warning("‚ö†Ô∏è No hay variables num√©ricas para analizar")
            return {}
        
        print("\n" + "üìä AN√ÅLISIS DE VARIABLES NUM√âRICAS")
        print("-" * 50)
        
        # Estad√≠sticas extendidas
        stats_df = self.df[self.numeric_columns].describe(percentiles=[.01, .25, .5, .75, .95, .99]).T
        
        # Calcular estad√≠sticas adicionales
        stats_df['skewness'] = self.df[self.numeric_columns].skew()
        stats_df['kurtosis'] = self.df[self.numeric_columns].kurtosis()
        stats_df['cv'] = (stats_df['std'] / stats_df['mean']) * 100
        stats_df['iqr'] = stats_df['75%'] - stats_df['25%']
        
        # Detecci√≥n de outliers
        outlier_stats = {}
        for col in self.numeric_columns:
            Q1 = self.df[col].quantile(0.25)
            Q3 = self.df[col].quantile(0.75)
            IQR = Q3 - Q1
            lower_bound = Q1 - 1.5 * IQR
            upper_bound = Q3 + 1.5 * IQR
            
            outliers = self.df[(self.df[col] < lower_bound) | (self.df[col] > upper_bound)]
            outlier_stats[col] = {
                'count': len(outliers),
                'percentage': (len(outliers) / len(self.df)) * 100,
                'bounds': (lower_bound, upper_bound)
            }
        
        stats_df['outliers_count'] = [outlier_stats[col]['count'] for col in self.numeric_columns]
        stats_df['outliers_percent'] = [outlier_stats[col]['percentage'] for col in self.numeric_columns]
        
        # Mostrar estad√≠sticas formateadas
        display_stats = stats_df[['mean', 'std', 'min', '25%', '50%', '75%', 'max', 
                                 'skewness', 'cv', 'outliers_percent']].round(3)
        print(display_stats)
        
        # Identificar variables problem√°ticas
        self._identify_problematic_numeric_variables(stats_df)
        
        # Visualizaciones
        self._plot_numeric_distributions(save_plots, plot_dir)
        
        return {
            'descriptive_stats': stats_df,
            'outlier_analysis': outlier_stats
        }
    
    def _identify_problematic_numeric_variables(self, stats_df):
        """Identificar variables num√©ricas problem√°ticas"""
        print("\nüö® VARIABLES NUM√âRICAS PROBLEM√ÅTICAS:")
        
        high_skew = stats_df[abs(stats_df['skewness']) > 2]
        high_cv = stats_df[stats_df['cv'] > 100]
        high_outliers = stats_df[stats_df['outliers_percent'] > 5]
        
        if len(high_skew) > 0:
            print("   ‚Ä¢ Alta asimetr√≠a (|skew| > 2):")
            for col in high_skew.index:
                print(f"     - {col}: skewness = {high_skew.loc[col, 'skewness']:.2f}")
        
        if len(high_cv) > 0:
            print("   ‚Ä¢ Alta dispersi√≥n (CV > 100%):")
            for col in high_cv.index:
                print(f"     - {col}: CV = {high_cv.loc[col, 'cv']:.1f}%")
        
        if len(high_outliers) > 0:
            print("   ‚Ä¢ Muchos outliers (>5%):")
            for col in high_outliers.index:
                print(f"     - {col}: {high_outliers.loc[col, 'outliers_percent']:.1f}% outliers")
    
    def _plot_numeric_distributions(self, save_plots=False, plot_dir='eda_plots'):
        """Visualizar distribuciones num√©ricas"""
        key_numeric = ['precio_venta', 'area', 'habitaciones', 'banos', 'administracion']
        available_numeric = [col for col in key_numeric if col in self.numeric_columns]
        
        if not available_numeric:
            return
        
        n_cols = min(3, len(available_numeric))
        n_rows = (len(available_numeric) + n_cols - 1) // n_cols
        
        fig, axes = plt.subplots(n_rows * 2, n_cols, figsize=(18, n_rows * 8))
        fig.suptitle('DISTRIBUCI√ìN DE VARIABLES NUM√âRICAS CLAVE', 
                    fontsize=16, fontweight='bold', y=0.95)
        
        if n_rows == 1:
            axes = axes.reshape(1, -1)
        
        for i, col in enumerate(available_numeric):
            row_hist = (i // n_cols) * 2
            row_box = row_hist + 1
            col_pos = i % n_cols
            
            # Histograma
            if n_rows == 1:
                ax_hist = axes[col_pos] if n_cols > 1 else axes
                ax_box = axes[col_pos + n_cols] if n_cols > 1 else axes
            else:
                ax_hist = axes[row_hist, col_pos]
                ax_box = axes[row_box, col_pos]
            
            # Histograma con KDE
            self.df[col].hist(bins=30, ax=ax_hist, color=self.colors[0], 
                             alpha=0.7, edgecolor='black')
            ax_hist.set_title(f'Distribuci√≥n de {col}', fontweight='bold')
            ax_hist.set_xlabel(col)
            ax_hist.set_ylabel('Frecuencia')
            
            # A√±adir estad√≠sticas
            mean_val = self.df[col].mean()
            median_val = self.df[col].median()
            ax_hist.axvline(mean_val, color='red', linestyle='--', linewidth=2, 
                           label=f'Media: {mean_val:,.0f}')
            ax_hist.axvline(median_val, color='green', linestyle='--', linewidth=2, 
                           label=f'Mediana: {median_val:,.0f}')
            ax_hist.legend()
            
            # Boxplot
            self.df.boxplot(column=col, ax=ax_box, color=self.colors[1])
            ax_box.set_title(f'Boxplot de {col}', fontweight='bold')
        
        plt.tight_layout()
        
        if save_plots:
            plt.savefig(f'{plot_dir}/numeric_distributions.png', dpi=300, bbox_inches='tight')
        
        plt.show()
    
    def _analyze_categorical_variables(self, save_plots=False, plot_dir='eda_plots'):
        """An√°lisis de variables categ√≥ricas"""
        self.logger.info("üìä Analizando variables categ√≥ricas...")
        
        if not self.categorical_columns:
            self.logger.warning("‚ö†Ô∏è No hay variables categ√≥ricas para analizar")
            return {}
        
        print("\n" + "üìù AN√ÅLISIS DE VARIABLES CATEG√ìRICAS")
        print("-" * 50)
        
        categorical_stats = {}
        
        for col in self.categorical_columns:
            print(f"\nüìå {col.upper()}:")
            
            value_counts = self.df[col].value_counts()
            n_categories = self.df[col].nunique()
            n_missing = self.df[col].isnull().sum()
            
            print(f"   ‚Ä¢ Categor√≠as √∫nicas: {n_categories}")
            print(f"   ‚Ä¢ Valores faltantes: {n_missing}")
            print(f"   ‚Ä¢ Top 5 categor√≠as:")
            
            top_5 = value_counts.head(5)
            for category, count in top_5.items():
                percentage = (count / len(self.df)) * 100
                print(f"     - {category}: {count} ({percentage:.1f}%)")
            
            # Precio promedio por categor√≠a si existe precio_venta
            if 'precio_venta' in self.df.columns:
                price_stats = self.df.groupby(col)['precio_venta'].agg(['mean', 'count']).round(0)
                top_prices = price_stats.nlargest(3, 'mean')
                
                if len(top_prices) > 0:
                    print(f"   üí∞ Top 3 categor√≠as por precio:")
                    for category, row in top_prices.iterrows():
                        print(f"     - {category}: ${row['mean']:,.0f} (n={row['count']})")
            
            categorical_stats[col] = {
                'n_categories': n_categories,
                'n_missing': n_missing,
                'value_counts': value_counts,
                'top_categories': top_5
            }
        
        # Visualizaciones
        self._plot_categorical_distributions(save_plots, plot_dir)
        
        return categorical_stats
    
    def _plot_categorical_distributions(self, save_plots=False, plot_dir='eda_plots'):
        """Visualizar distribuciones categ√≥ricas"""
        key_categorical = ['tipo_propiedad', 'estrato', 'antiguedad', 'localidad']
        available_categorical = [col for col in key_categorical if col in self.categorical_columns]
        
        if not available_categorical:
            return
        
        n_cols = 2
        n_rows = (len(available_categorical) + 1) // 2
        
        fig, axes = plt.subplots(n_rows, n_cols, figsize=(16, n_rows * 5))
        fig.suptitle('DISTRIBUCI√ìN DE VARIABLES CATEG√ìRICAS CLAVE', 
                    fontsize=16, fontweight='bold', y=0.95)
        
        if n_rows == 1:
            axes = axes.reshape(1, -1)
        
        for i, col in enumerate(available_categorical):
            row = i // n_cols
            col_pos = i % n_cols
            
            if n_rows == 1:
                ax = axes[col_pos]
            else:
                ax = axes[row, col_pos]
            
            # Tomar top 10 categor√≠as
            top_categories = self.df[col].value_counts().head(10)
            
            bars = ax.bar(top_categories.index.astype(str), top_categories.values, 
                         color=self.colors[i % len(self.colors)], alpha=0.7, edgecolor='black')
            
            ax.set_title(f'Distribuci√≥n de {col}', fontweight='bold', pad=20)
            ax.set_xlabel(col)
            ax.set_ylabel('Frecuencia')
            ax.tick_params(axis='x', rotation=45)
            
            # A√±adir etiquetas
            for bar in bars:
                height = bar.get_height()
                ax.text(bar.get_x() + bar.get_width()/2., height + 0.5,
                       f'{height:,}', ha='center', va='bottom', fontsize=9)
        
        # Ocultar ejes vac√≠os
        for i in range(len(available_categorical), n_rows * n_cols):
            row = i // n_cols
            col_pos = i % n_cols
            if n_rows == 1:
                axes[col_pos].set_visible(False)
            else:
                axes[row, col_pos].set_visible(False)
        
        plt.tight_layout()
        
        if save_plots:
            plt.savefig(f'{plot_dir}/categorical_distributions.png', dpi=300, bbox_inches='tight')
        
        plt.show()
    
    def _analyze_correlations(self, save_plots=False, plot_dir='eda_plots'):
        """An√°lisis de correlaciones entre variables num√©ricas"""
        self.logger.info("üîó Analizando correlaciones...")
        
        if len(self.numeric_columns) < 2:
            self.logger.warning("‚ö†Ô∏è No hay suficientes variables num√©ricas para an√°lisis de correlaci√≥n")
            return {}
        
        print("\n" + "üîó AN√ÅLISIS DE CORRELACIONES")
        print("-" * 50)
        
        # Matriz de correlaci√≥n
        correlation_matrix = self.df[self.numeric_columns].corr()
        
        print("üìä MATRIZ DE CORRELACI√ìN (Pearson):")
        print(correlation_matrix.round(3))
        
        # Correlaciones fuertes con precio_venta
        if 'precio_venta' in correlation_matrix.columns:
            price_correlations = correlation_matrix['precio_venta'].sort_values(ascending=False)
            
            print("\nüí™ CORRELACIONES CON PRECIO_VENTA:")
            for var, corr in price_correlations.items():
                if var != 'precio_venta':
                    strength = "FUERTE ‚Üó" if corr > 0.7 else "MODERADA ‚Üí" if corr > 0.3 else "D√âBIL ‚Üò"
                    print(f"   ‚Ä¢ {var}: {corr:.3f} ({strength})")
        
        # Visualizaci√≥n
        self._plot_correlation_heatmap(correlation_matrix, save_plots, plot_dir)
        
        # Detectar correlaciones altas
        high_corr_pairs = []
        for i in range(len(correlation_matrix.columns)):
            for j in range(i+1, len(correlation_matrix.columns)):
                if abs(correlation_matrix.iloc[i, j]) > 0.8:
                    high_corr_pairs.append((
                        correlation_matrix.columns[i],
                        correlation_matrix.columns[j],
                        correlation_matrix.iloc[i, j]
                    ))
        
        if high_corr_pairs:
            print("\nüö® CORRELACIONES MUY ALTAS (>0.8):")
            for var1, var2, corr in high_corr_pairs:
                print(f"   ‚ö†Ô∏è  {var1} ‚Üî {var2}: r = {corr:.3f}")
        
        return {
            'correlation_matrix': correlation_matrix,
            'high_correlation_pairs': high_corr_pairs
        }
    
    def _plot_correlation_heatmap(self, corr_matrix, save_plots=False, plot_dir='eda_plots'):
        """Visualizar matriz de correlaci√≥n"""
        plt.figure(figsize=(12, 10))
        
        mask = np.triu(np.ones_like(corr_matrix, dtype=bool))
        
        sns.heatmap(corr_matrix, 
                   mask=mask,
                   annot=True, 
                   cmap='RdBu_r', 
                   center=0,
                   square=True,
                   fmt='.2f',
                   cbar_kws={'shrink': .8},
                   linewidths=0.5)
        
        plt.title('MATRIZ DE CORRELACI√ìN - VARIABLES NUM√âRICAS', 
                 fontsize=16, fontweight='bold', pad=20)
        
        plt.tight_layout()
        
        if save_plots:
            plt.savefig(f'{plot_dir}/correlation_heatmap.png', dpi=300, bbox_inches='tight')
        
        plt.show()
    
    def _analyze_price_relationships(self, save_plots=False, plot_dir='eda_plots'):
        """Analizar relaciones con precio_venta"""
        self.logger.info("üí∞ Analizando relaciones con precio...")
        
        if 'precio_venta' not in self.df.columns:
            self.logger.warning("‚ö†Ô∏è Variable precio_venta no encontrada")
            return {}
        
        print("\n" + "üí∞ RELACIONES CON PRECIO DE VENTA")
        print("-" * 50)
        
        # Variables para an√°lisis de relaciones
        relationship_vars = ['area', 'habitaciones', 'banos', 'administracion']
        available_relationship_vars = [col for col in relationship_vars if col in self.numeric_columns]
        
        if not available_relationship_vars:
            return {}
        
        n_cols = 2
        n_rows = (len(available_relationship_vars) + 1) // 2
        
        fig, axes = plt.subplots(n_rows, n_cols, figsize=(16, n_rows * 6))
        fig.suptitle('RELACIONES CON PRECIO DE VENTA', 
                    fontsize=16, fontweight='bold', y=0.95)
        
        if n_rows == 1:
            axes = axes.reshape(1, -1)
        
        correlation_results = {}
        
        for i, var in enumerate(available_relationship_vars):
            row = i // n_cols
            col_pos = i % n_cols
            
            if n_rows == 1:
                ax = axes[col_pos]
            else:
                ax = axes[row, col_pos]
            
            # Scatter plot
            ax.scatter(self.df[var], self.df['precio_venta'], 
                      alpha=0.6, color=self.colors[2], s=50)
            ax.set_xlabel(var)
            ax.set_ylabel('Precio Venta')
            ax.set_title(f'{var} vs Precio', fontweight='bold')
            
            # Calcular correlaci√≥n
            valid_data = self.df[[var, 'precio_venta']].dropna()
            if len(valid_data) > 1:
                corr = valid_data[var].corr(valid_data['precio_venta'])
                correlation_results[var] = corr
                
                # A√±adir l√≠nea de tendencia
                z = np.polyfit(valid_data[var], valid_data['precio_venta'], 1)
                p = np.poly1d(z)
                ax.plot(valid_data[var], p(valid_data[var]), "r--", alpha=0.8, linewidth=2)
                
                # A√±adir texto de correlaci√≥n
                ax.text(0.05, 0.95, f'Correlaci√≥n: {corr:.3f}', 
                       transform=ax.transAxes, fontsize=12, fontweight='bold',
                       bbox=dict(boxstyle="round,pad=0.3", facecolor="white", alpha=0.8))
        
        # Ocultar ejes vac√≠os
        for i in range(len(available_relationship_vars), n_rows * n_cols):
            row = i // n_cols
            col_pos = i % n_cols
            if n_rows == 1:
                axes[col_pos].set_visible(False)
            else:
                axes[row, col_pos].set_visible(False)
        
        plt.tight_layout()
        
        if save_plots:
            plt.savefig(f'{plot_dir}/price_relationships.png', dpi=300, bbox_inches='tight')
        
        plt.show()
        
        return correlation_results
    
    def _detect_potential_issues(self, missing_analysis, numeric_stats):
        """Detecci√≥n sistem√°tica de problemas potenciales"""
        self.logger.info("üö® Detectando problemas potenciales...")
        
        print("\n" + "üö® DETECCI√ìN DE PROBLEMAS POTENCIALES")
        print("-" * 50)
        
        issues = {
            'missing_values': [],
            'outliers': [],
            'skewness': [],
            'high_correlation': [],
            'categorical_issues': []
        }
        
        # 1. Valores faltantes cr√≠ticos
        if len(missing_analysis) > 0:
            high_missing = missing_analysis[missing_analysis['Porcentaje'] > 30]
            if len(high_missing) > 0:
                issues['missing_values'].append("Columnas con >30% valores faltantes:")
                for col in high_missing.index:
                    issues['missing_values'].append(f"  - {col}: {high_missing.loc[col, 'Porcentaje']:.1f}%")
        
        # 2. Outliers extremos
        if hasattr(numeric_stats, 'index'):
            high_outliers = numeric_stats[numeric_stats['outliers_percent'] > 10]
            if len(high_outliers) > 0:
                issues['outliers'].append("Variables con >10% outliers:")
                for col in high_outliers.index:
                    issues['outliers'].append(f"  - {col}: {high_outliers.loc[col, 'outliers_percent']:.1f}%")
        
        # 3. Distribuciones sesgadas
        if hasattr(numeric_stats, 'index'):
            high_skew = numeric_stats[abs(numeric_stats['skewness']) > 3]
            if len(high_skew) > 0:
                issues['skewness'].append("Variables muy sesgadas (|skew| > 3):")
                for col in high_skew.index:
                    issues['skewness'].append(f"  - {col}: skewness = {high_skew.loc[col, 'skewness']:.2f}")
        
        # 4. Problemas categ√≥ricos
        for col in self.categorical_columns:
            n_categories = self.df[col].nunique()
            if n_categories > 50:
                issues['categorical_issues'].append(f"  - {col}: {n_categories} categor√≠as (demasiadas)")
        
        # Mostrar problemas detectados
        for category, problem_list in issues.items():
            if problem_list:
                print(f"\nüî¥ {category.upper().replace('_', ' ')}:")
                for problem in problem_list:
                    print(f"   {problem}")
        
        if all(len(v) == 0 for v in issues.values()):
            print("‚úÖ No se detectaron problemas cr√≠ticos")
        
        return issues
    
    def _provide_preprocessing_recommendations(self, issues, numeric_stats, missing_analysis):
        """Proporcionar recomendaciones de preprocesamiento"""
        self.logger.info("üéØ Generando recomendaciones...")
        
        print("\n" + "üéØ RECOMENDACIONES DE PREPROCESAMIENTO")
        print("-" * 50)
        
        print("1Ô∏è‚É£ MANEJO DE VALORES FALTANTES:")
        if issues['missing_values']:
            high_missing = missing_analysis[missing_analysis['Porcentaje'] > 50]
            if len(high_missing) > 0:
                print("   üóëÔ∏è  ELIMINAR columnas con >50% faltantes:")
                for col in high_missing.index:
                    print(f"     ‚Ä¢ {col}")
            
            moderate_missing = missing_analysis[(missing_analysis['Porcentaje'] > 5) & 
                                              (missing_analysis['Porcentaje'] <= 50)]
            if len(moderate_missing) > 0:
                print("   üîß IMPUTAR columnas con 5-50% faltantes:")
                for col in moderate_missing.index:
                    if col in self.numeric_columns:
                        print(f"     ‚Ä¢ {col}: Imputar con mediana")
                    else:
                        print(f"     ‚Ä¢ {col}: Imputar con moda o 'DESCONOCIDO'")
        else:
            print("   ‚úÖ No se requieren acciones para valores faltantes")
        
        print("\n2Ô∏è‚É£ TRANSFORMACI√ìN DE VARIABLES:")
        if issues['skewness'] and hasattr(numeric_stats, 'index'):
            skewed_vars = numeric_stats[abs(numeric_stats['skewness']) > 2].index
            if len(skewed_vars) > 0:
                print("   üìà APLICAR transformaci√≥n logar√≠tmica a:")
                for var in skewed_vars:
                    print(f"     ‚Ä¢ {var}")
        
        if issues['outliers'] and hasattr(numeric_stats, 'index'):
            outlier_vars = numeric_stats[numeric_stats['outliers_percent'] > 5].index
            if len(outlier_vars) > 0:
                print("   üìä APLICAR winsorization (1%-99%) a:")
                for var in outlier_vars:
                    print(f"     ‚Ä¢ {var}")
        
        print("\n3Ô∏è‚É£ CODIFICACI√ìN DE VARIABLES CATEG√ìRICAS:")
        for col in self.categorical_columns:
            n_categories = self.df[col].nunique()
            if n_categories <= 10:
                print(f"   üî§ {col}: One-Hot Encoding ({n_categories} categor√≠as)")
            elif n_categories <= 20:
                print(f"   üî§ {col}: Target Encoding ({n_categories} categor√≠as)")
            else:
                print(f"   üî§ {col}: Agrupar + Frequency Encoding ({n_categories} categor√≠as)")
        
        print("\n4Ô∏è‚É£ FILTRADO Y LIMPIEZA:")
        print("   üéØ Aplicar filtros b√°sicos:")
        print("     ‚Ä¢ precio_venta > 0")
        print("     ‚Ä¢ area > 0")
        print("     ‚Ä¢ Coordenadas dentro de Bogot√°")
        print("     ‚Ä¢ Estrato entre 1 y 6")
        
        print("\n5Ô∏è‚É£ INGENIER√çA DE CARACTER√çSTICAS:")
        print("   üõ†Ô∏è  Crear nuevas variables:")
        print("     ‚Ä¢ precio_m2 = precio_venta / area")
        print("     ‚Ä¢ amenities_score = suma de amenities")
        print("     ‚Ä¢ ratios: banos_por_area, habitaciones_por_area")
    
    def _generate_executive_summary(self, missing_analysis, numeric_stats, issues):
        """Generar resumen ejecutivo final"""
        print("\n" + "‚≠ê" * 50)
        print("‚≠ê RESUMEN EJECUTIVO - DIAGN√ìSTICO FINAL")
        print("‚≠ê" * 50)
        
        # Calcular m√©tricas clave
        total_issues = sum(len(v) for v in issues.values())
        data_quality_score = max(0, 10 - total_issues * 0.5)
        
        print(f"\nüìä M√âTRICAS CLAVE:")
        print(f"   ‚Ä¢ Registros totales: {self.df.shape[0]:,}")
        print(f"   ‚Ä¢ Variables analizadas: {self.df.shape[1]}")
        print(f"   ‚Ä¢ Calidad de datos: {data_quality_score:.1f}/10")
        
        if 'precio_venta' in self.df.columns:
            price_stats = self.df['precio_venta'].describe()
            print(f"   ‚Ä¢ Rango de precios: ${price_stats['min']:,.0f} - ${price_stats['max']:,.0f}")
        
        print(f"\nüö® PROBLEMAS IDENTIFICADOS: {total_issues}")
        for category, problem_list in issues.items():
            if problem_list:
                print(f"   ‚Ä¢ {category}: {len(problem_list)}")
        
        print(f"\nüí° RECOMENDACIONES PRIORITARIAS:")
        print("   1. Limpieza de outliers en variables clave")
        print("   2. Transformaci√≥n de variables sesgadas")
        print("   3. Imputaci√≥n inteligente de valores faltantes")
        print("   4. Codificaci√≥n apropiada de categ√≥ricas")
        
        print(f"\nüìà PREPARACI√ìN PARA MODELADO:")
        if data_quality_score >= 7:
            print("   ‚úÖ CALIDAD ALTA: Listo para preprocesamiento est√°ndar")
        elif data_quality_score >= 5:
            print("   ‚ö†Ô∏è  CALIDAD MEDIA: Requiere preprocesamiento moderado")
        else:
            print("   üî¥ CALIDAD BAJA: Requiere limpieza extensiva")
        
        print(f"\nüéØ PR√ìXIMOS PASOS:")
        print("   1. Implementar pipeline de preprocesamiento")
        print("   2. Validar calidad despu√©s de limpieza")
        print("   3. Realizar feature engineering")
        print("   4. Entrenar modelos baseline")


# Funci√≥n de conveniencia para uso r√°pido
def run_complete_eda(file_path, save_plots=False):
    """
    Ejecutar an√°lisis EDA completo con una sola funci√≥n
    
    Args:
        file_path (str): Ruta al archivo Excel
        save_plots (bool): Guardar gr√°ficos en archivos
    
    Returns:
        dict: Resultados del an√°lisis
    """
    eda = BogotaApartmentsEDA(file_path)
    return eda.generate_complete_report(save_plots=save_plots)


if __name__ == "__main__":
    # Ejemplo de uso
    sample_file = "bogota_apartments.xlsx"
    
    try:
        # Uso simple
        results = run_complete_eda(sample_file, save_plots=True)
        print("‚úÖ An√°lisis EDA completado exitosamente")
        
    except Exception as e:
        print(f"‚ùå Error en el an√°lisis EDA: {e}")